# CIFAR-10 成员推断攻击项目

本项目实现了一个针对 CIFAR-10 数据集上训练的卷积神经网络（CNN）进行的成员推断攻击（Membership Inference Attack, MIA）。成员推断攻击旨在推测某数据点是否被用于目标模型的训练过程，揭示潜在的隐私风险。本项目利用pytorch，通过训练影子模型和攻击模型来模拟这一攻击过程。

代码复现于论文"ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models"中的敌手1.

## 项目概述

项目主要包含以下步骤：
1. **数据划分**：将 CIFAR-10 数据集分为多个子集，用于训练影子模型和目标模型。
2. **影子模型**：基于 CIFAR-10 子集训练的 CNN，模拟目标模型的行为。
3. **目标模型**：基于另一子集训练的 CNN，作为攻击目标。
4. **攻击模型**：一个多层感知器（MLP），利用影子模型输出的 top-k 后验概率来判断数据点是否为训练集成员。
5. **训练与评估**：提供训练和评估分类器模型及攻击模型的功能，输出模型性能和攻击成功率。

## 文件结构

- **`main.py`**：主脚本，负责协调影子模型、目标模型和攻击模型的训练与评估。
- **`model.py`**：定义了 `ShadowModel`（用于 CIFAR-10 分类的 CNN）和 `AttackModel`（用于成员推断的 MLP）。
- **`dataloader.py`**：处理 CIFAR-10 数据集的加载、预处理和划分。
- **`train_eval.py`**：包含训练和评估分类器及攻击模型的函数。

## 配置参数

在 `main.py` 中可以调整以下主要参数：

- `batch_size`：训练批大小为 64，测试批大小为 1000。
- `shadow_epochs`：影子模型训练 20 个 epoch。
- `target_epochs`：目标模型训练 20 个 epoch。
- `attack_epochs`：攻击模型训练 50 个 epoch。
- `device`：自动检测并使用 CUDA（若 GPU 可用），否则使用 CPU。
- `model_dir`：模型保存路径，默认为 `./models`。

您可以修改这些参数以进行不同的实验配置。

## 模型架构

### 影子模型与目标模型
- **类型**：卷积神经网络（CNN）。
- **结构**：
  - 两个卷积层（3→32 和 32→64，3x3 卷积核，padding=1）。
  - 最大池化层（2x2，步幅 2）。
  - 三个全连接层（4096→256→128→10）。
  - Dropout 层（丢弃概率 0.5）。
- **输入**：CIFAR-10 图像（3x32x32）。
- **输出**：10 类分类概率（对应 CIFAR-10 的 10 个类别）。
- **优化器**：Adam，学习率 0.001。
- **损失函数**：交叉熵损失（CrossEntropyLoss）。

### 攻击模型
- **类型**：多层感知器（MLP）。
- **结构**：
  - 三个全连接层（input_size=3→32→16→1）。
  - Sigmoid 激活函数。
- **输入**：影子或目标模型输出的 top-3 后验概率。
- **输出**：Sigmoid 概率（1 表示成员，0 表示非成员）。
- **优化器**：Adam，学习率 0.001。
- **损失函数**：二元交叉熵损失（BCELoss）。

## 数据划分

CIFAR-10 训练集（50,000 张图像）被均分为四个子集，每子集包含 12,500 张图像：
- `shadow_train`：用于训练影子模型。
- `shadow_out`：影子模型的非成员数据，用于攻击模型训练。
- `target_train`：用于训练目标模型。
- `target_out`：目标模型的非成员数据，用于攻击模型评估。

CIFAR-10 测试集（10,000 张图像）用于评估影子模型和目标模型的分类性能。
